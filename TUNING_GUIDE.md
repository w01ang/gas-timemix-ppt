# TimeMixer è°ƒå‚æŒ‡å—

## ğŸ“‹ å®Œæ•´å‚æ•°åˆ—è¡¨

### å¿…éœ€å‚æ•°
| å‚æ•° | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|
| `--model_id` | str | å®éªŒå”¯ä¸€æ ‡è¯†ç¬¦ | `slide_optimized_v4` |
| `--input_len` | int | è¾“å…¥åºåˆ—é•¿åº¦ | `3000` |
| `--output_len` | int | è¾“å‡ºåºåˆ—é•¿åº¦ | `1000` |

### æ•°æ®å‚æ•°
| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--root_path` | str | `/Users/wangjr/Documents/yk/timemixer/data` | æ•°æ®é›†æ ¹ç›®å½• |
| `--data_path` | str | `preprocessed_daily_gas_by_well.csv` | æ•°æ®é›†æ–‡ä»¶å |
| `--step_len` | int | `output_len` | æ»‘åŠ¨çª—å£æ­¥é•¿ |

### æ¨¡å‹æ¶æ„å‚æ•°
| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | å»ºè®®èŒƒå›´ | è¯´æ˜ |
|------|------|--------|----------|------|
| `--d_model` | int | 256 | 32-128 | æ¨¡å‹ç»´åº¦ï¼ˆè¶Šå°è¶Šé˜²è¿‡æ‹Ÿåˆï¼‰ |
| `--n_heads` | int | 16 | 2-8 | æ³¨æ„åŠ›å¤´æ•°ï¼ˆå¿…é¡»èƒ½æ•´é™¤d_modelï¼‰ |
| `--e_layers` | int | 6 | 1-3 | ç¼–ç å™¨å±‚æ•° |
| `--d_layers` | int | 3 | 1-2 | è§£ç å™¨å±‚æ•° |
| `--d_ff` | int | 1024 | 128-512 | å‰é¦ˆç½‘ç»œç»´åº¦ï¼ˆé€šå¸¸=d_modelÃ—4ï¼‰ |
| `--dropout` | float | 0.1 | 0.1-0.5 | Dropoutæ¯”ä¾‹ï¼ˆè¶Šå¤§è¶Šé˜²è¿‡æ‹Ÿåˆï¼‰ |

### è®­ç»ƒå‚æ•°
| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | å»ºè®®èŒƒå›´ | è¯´æ˜ |
|------|------|--------|----------|------|
| `--train_epochs` | int | 100 | 50-100 | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | 8 | 8-32 | æ‰¹å¤§å°ï¼ˆè¶Šå¤§è¶Šç¨³å®šï¼‰ |
| `--patience` | int | 20 | 10-25 | æ—©åœè€å¿ƒå€¼ |
| `--learning_rate` | float | 1e-4 | 5e-5 to 1e-4 | åˆå§‹å­¦ä¹ ç‡ |
| `--use_gpu` | flag | False | - | å¯ç”¨GPU/MPSåŠ é€Ÿ |

---

## ğŸ¯ è°ƒå‚ç­–ç•¥

### é—®é¢˜1ï¼šè¿‡æ‹Ÿåˆï¼ˆè®­ç»ƒæŸå¤±<<éªŒè¯æŸå¤±ï¼‰

**ç—‡çŠ¶ï¼š**
```
Epoch 30:
  è®­ç»ƒæŸå¤±: 0.05   â† å¾ˆä½
  éªŒè¯æŸå¤±: 0.45   â† å¾ˆé«˜
  å·®è·: 0.40       â† å¤ªå¤§ï¼
```

**è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š**

1. **é™ä½æ¨¡å‹å¤æ‚åº¦** â­â­â­â­â­
   ```bash
   --d_model 64      # ä» 256 é™åˆ° 64
   --n_heads 4       # ä» 16 é™åˆ° 4
   --e_layers 2      # ä» 6 é™åˆ° 2
   --d_layers 1      # ä» 3 é™åˆ° 1
   --d_ff 256        # ä» 1024 é™åˆ° 256
   ```

2. **å¢åŠ æ­£åˆ™åŒ–** â­â­â­â­
   ```bash
   --dropout 0.25    # ä» 0.1 æå‡åˆ° 0.25-0.5
   ```

3. **å¢åŠ batch size** â­â­â­
   ```bash
   --batch_size 16   # ä» 8 æå‡åˆ° 16-32
   ```

4. **é™ä½å­¦ä¹ ç‡** â­â­
   ```bash
   --learning_rate 5e-5   # ä» 1e-4 é™åˆ° 5e-5
   ```

5. **å‡å°è¾“å…¥é•¿åº¦** â­â­
   ```bash
   --input_len 2000  # ä» 3000 é™åˆ° 2000
   ```

### é—®é¢˜2ï¼šæ¬ æ‹Ÿåˆï¼ˆè®­ç»ƒå’ŒéªŒè¯æŸå¤±éƒ½å¾ˆé«˜ï¼‰

**ç—‡çŠ¶ï¼š**
```
Epoch 30:
  è®­ç»ƒæŸå¤±: 0.50   â† å¾ˆé«˜
  éªŒè¯æŸå¤±: 0.52   â† ä¹Ÿå¾ˆé«˜
  å·®è·: 0.02       â† å¾ˆå°ä½†æ•ˆæœå·®
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **å¢åŠ æ¨¡å‹å¤æ‚åº¦** â­â­â­â­â­
   ```bash
   --d_model 128     # å¢åŠ åˆ° 128
   --n_heads 8       # å¢åŠ åˆ° 8
   --e_layers 3      # å¢åŠ åˆ° 3
   ```

2. **æé«˜å­¦ä¹ ç‡** â­â­â­â­
   ```bash
   --learning_rate 2e-4  # æå‡åˆ° 2e-4
   ```

3. **å¢åŠ è®­ç»ƒè½®æ•°** â­â­â­
   ```bash
   --train_epochs 150
   --patience 30
   ```

4. **å‡å°dropout** â­â­
   ```bash
   --dropout 0.05    # é™ä½åˆ° 0.05
   ```

### é—®é¢˜3ï¼šè®­ç»ƒä¸ç¨³å®šï¼ˆéªŒè¯æŸå¤±å‰§çƒˆæ³¢åŠ¨ï¼‰

**ç—‡çŠ¶ï¼š**
```
éªŒè¯æŸå¤±æ ‡å‡†å·® > 0.3
éªŒè¯æŸå¤±åœ¨ 0.3 å’Œ 1.5 ä¹‹é—´è·³åŠ¨
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **å¢åŠ batch size** â­â­â­â­â­
   ```bash
   --batch_size 32   # æ›´å¤§çš„batch
   ```

2. **é™ä½å­¦ä¹ ç‡** â­â­â­â­
   ```bash
   --learning_rate 5e-5
   ```

3. **å‡å°step_lenï¼ˆå¢åŠ æ ·æœ¬å¤šæ ·æ€§ï¼‰** â­â­â­
   ```bash
   --step_len 50     # åˆ›å»ºæ›´å¤šé‡å æ ·æœ¬
   ```

4. **é™ä½æ¨¡å‹å¤æ‚åº¦** â­â­
   ```bash
   --d_model 64
   ```

---

## ğŸš€ æ¨èé…ç½®æ–¹æ¡ˆ

### æ–¹æ¡ˆAï¼šç¨³å¥å‹ï¼ˆé’ˆå¯¹å½“å‰è¿‡æ‹Ÿåˆé—®é¢˜ï¼‰â­â­â­â­â­

```bash
python scripts/train_sliding_window.py \
  --model_id slide_optimized_v4 \
  --input_len 3000 \
  --output_len 1000 \
  --step_len 50 \
  --batch_size 16 \
  --d_model 64 \
  --n_heads 4 \
  --e_layers 2 \
  --d_layers 1 \
  --d_ff 256 \
  --dropout 0.25 \
  --learning_rate 8e-5 \
  --patience 15 \
  --train_epochs 50 \
  --use_gpu
```

**é¢„æœŸæ•ˆæœï¼š**
- æµ‹è¯•æŸå¤±ï¼š0.36-0.38
- è¿‡æ‹Ÿåˆå·®è·ï¼š< 0.15
- éªŒè¯æŸå¤±æ³¢åŠ¨ï¼š< 0.2

### æ–¹æ¡ˆBï¼šè½»é‡å‹ï¼ˆå¦‚æœæ–¹æ¡ˆAè¿˜è¿‡æ‹Ÿåˆï¼‰

```bash
python scripts/train_sliding_window.py \
  --model_id slide_lighter_v4 \
  --input_len 3000 \
  --output_len 1000 \
  --step_len 50 \
  --batch_size 32 \
  --d_model 48 \
  --n_heads 4 \
  --e_layers 2 \
  --d_layers 1 \
  --d_ff 192 \
  --dropout 0.3 \
  --learning_rate 1e-4 \
  --patience 20 \
  --train_epochs 60 \
  --use_gpu
```

### æ–¹æ¡ˆCï¼šå¹³è¡¡å‹ï¼ˆè°ƒæ•´è¾“å…¥è¾“å‡ºæ¯”ä¾‹ï¼‰

```bash
python scripts/train_sliding_window.py \
  --model_id slide_balanced_in2400_out600 \
  --input_len 2400 \
  --output_len 600 \
  --step_len 300 \
  --batch_size 16 \
  --d_model 64 \
  --n_heads 4 \
  --e_layers 2 \
  --d_layers 1 \
  --d_ff 256 \
  --dropout 0.25 \
  --learning_rate 8e-5 \
  --patience 15 \
  --train_epochs 50 \
  --use_gpu
```

### æ–¹æ¡ˆDï¼šæç®€å‹ï¼ˆä¿åº•æ–¹æ¡ˆï¼‰

```bash
python scripts/train_sliding_window.py \
  --model_id slide_minimal_v4 \
  --input_len 1600 \
  --output_len 400 \
  --step_len 200 \
  --batch_size 32 \
  --d_model 32 \
  --n_heads 2 \
  --e_layers 2 \
  --d_layers 1 \
  --d_ff 128 \
  --dropout 0.4 \
  --learning_rate 1e-4 \
  --patience 25 \
  --train_epochs 80 \
  --use_gpu
```

---

## ğŸ“Š å¦‚ä½•è¯„ä¼°è®­ç»ƒæ•ˆæœ

### å¥åº·çš„è®­ç»ƒæ›²çº¿

```
Epoch 20:
  Train Loss: 0.15
  Vali Loss:  0.18
  Test Loss:  0.17
  Gap: 0.03 âœ…
```

**ç‰¹å¾ï¼š**
- âœ… è®­ç»ƒ/éªŒè¯æŸå¤±å·®è· < 0.1
- âœ… éªŒè¯æŸå¤±å¹³æ»‘ä¸‹é™
- âœ… æµ‹è¯•æŸå¤±æ¥è¿‘éªŒè¯æŸå¤±
- âœ… éªŒè¯æŸå¤±æ ‡å‡†å·® < 0.1

### è¿‡æ‹Ÿåˆçš„è®­ç»ƒæ›²çº¿

```
Epoch 30:
  Train Loss: 0.05
  Vali Loss:  0.45
  Test Loss:  0.42
  Gap: 0.40 âŒ
```

**ç‰¹å¾ï¼š**
- âŒ è®­ç»ƒ/éªŒè¯æŸå¤±å·®è· > 0.3
- âŒ è®­ç»ƒæŸå¤±æŒç»­ä¸‹é™ï¼ŒéªŒè¯æŸå¤±åå¼¹
- âŒ éªŒè¯æŸå¤±å‰§çƒˆæ³¢åŠ¨
- âŒ æœ€ä½³epochå‡ºç°åœ¨æ—©æœŸï¼ˆå‰20%è½®æ¬¡ï¼‰

### æ¬ æ‹Ÿåˆçš„è®­ç»ƒæ›²çº¿

```
Epoch 50:
  Train Loss: 0.45
  Vali Loss:  0.47
  Test Loss:  0.46
  Gap: 0.02 âš ï¸
```

**ç‰¹å¾ï¼š**
- âš ï¸ å·®è·å°ä½†æ‰€æœ‰æŸå¤±éƒ½å¾ˆé«˜
- âš ï¸ æŸå¤±ä¸‹é™ç¼“æ…¢æˆ–åœæ»
- âš ï¸ æ¥è¿‘è®­ç»ƒç»“æŸä»åœ¨æ”¹å–„

---

## ğŸ”¬ é«˜çº§è°ƒå‚æŠ€å·§

### 1. å‚æ•°ç»„åˆè§„åˆ™

**n_heads å¿…é¡»èƒ½æ•´é™¤ d_modelï¼š**
```bash
# âœ… æ­£ç¡®
--d_model 64 --n_heads 4    # 64 / 4 = 16
--d_model 48 --n_heads 4    # 48 / 4 = 12

# âŒ é”™è¯¯
--d_model 64 --n_heads 5    # 64 / 5 = 12.8 (ä¸æ•´é™¤)
```

**d_ff é€šå¸¸æ˜¯ d_model çš„ 2-4 å€ï¼š**
```bash
--d_model 64 --d_ff 256     # 4å€
--d_model 48 --d_ff 192     # 4å€
--d_model 32 --d_ff 128     # 4å€
```

### 2. step_len ä¸æ ·æœ¬æ•°é‡

```bash
# å‡è®¾äº•é•¿ = 5000ï¼Œinput_len = 3000ï¼Œoutput_len = 1000

--step_len 1000  # æ¯å£äº•ç”Ÿæˆ ~2 ä¸ªæ ·æœ¬ï¼ˆæ— é‡å ï¼‰
--step_len 500   # æ¯å£äº•ç”Ÿæˆ ~4 ä¸ªæ ·æœ¬ï¼ˆ50%é‡å ï¼‰
--step_len 100   # æ¯å£äº•ç”Ÿæˆ ~20 ä¸ªæ ·æœ¬ï¼ˆ90%é‡å ï¼‰
```

**å»ºè®®ï¼š**
- æ•°æ®å°‘æ—¶ï¼š`step_len = output_len / 2` ï¼ˆ50%é‡å ï¼‰
- æ•°æ®å……è¶³æ—¶ï¼š`step_len = output_len` ï¼ˆæ— é‡å ï¼‰

### 3. æ¸è¿›å¼è°ƒå‚æµç¨‹

```
1. ä»æç®€æ¨¡å‹å¼€å§‹
   â†“ (d_model=32, dropout=0.4)
2. è§‚å¯Ÿæ˜¯å¦æ¬ æ‹Ÿåˆ
   â†“
3. å¦‚æœæ¬ æ‹Ÿåˆ â†’ é€æ­¥å¢åŠ å¤æ‚åº¦
   â†“ (d_model=48 â†’ 64 â†’ 128)
4. ç›´åˆ°å‡ºç°è½»å¾®è¿‡æ‹Ÿåˆ
   â†“
5. å¢åŠ dropoutå¹¶å¾®è°ƒ
   â†“ (dropout=0.25)
6. æ‰¾åˆ°æœ€ä½³å¹³è¡¡ç‚¹ âœ…
```

---

## ğŸ“ˆ å®éªŒè®°å½•æ¨¡æ¿

å»ºè®®åˆ›å»ºä¸€ä¸ªå®éªŒæ—¥å¿—è¡¨æ ¼ï¼š

| å®éªŒID | d_model | dropout | batch_size | æœ€ä½³æµ‹è¯•æŸå¤± | è¿‡æ‹Ÿåˆå·®è· | å¤‡æ³¨ |
|--------|---------|---------|------------|--------------|-----------|------|
| v1 | 256 | 0.1 | 8 | 0.422 | 0.609 | ä¸¥é‡è¿‡æ‹Ÿåˆ |
| v2 | 256 | 0.1 | 16 | 0.390 | 0.479 | ä»è¿‡æ‹Ÿåˆ |
| v3 | 64 | 0.1 | 16 | 0.397 | 0.412 | æ”¹å–„ä½†ä¸å¤Ÿ |
| v4 | 64 | 0.25 | 16 | ? | ? | å¾…æµ‹è¯• |

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆé™ä½d_modelå°±èƒ½é˜²æ­¢è¿‡æ‹Ÿåˆï¼Ÿ
A: d_modelå†³å®šäº†æ¨¡å‹çš„å‚æ•°é‡ã€‚å‚æ•°è¶Šå¤šï¼Œæ¨¡å‹"è®°å¿†"è®­ç»ƒæ•°æ®çš„èƒ½åŠ›è¶Šå¼ºï¼Œå¯¼è‡´è¿‡æ‹Ÿåˆã€‚

### Q2: dropoutåº”è¯¥è®¾ç½®å¤šå¤§ï¼Ÿ
A: 
- è½»åº¦è¿‡æ‹Ÿåˆï¼š0.15-0.2
- ä¸­åº¦è¿‡æ‹Ÿåˆï¼š0.25-0.3
- ä¸¥é‡è¿‡æ‹Ÿåˆï¼š0.3-0.5

### Q3: å¦‚ä½•é€‰æ‹©input_lenå’Œoutput_lenï¼Ÿ
A:
- æ¯”ä¾‹å»ºè®®ï¼š4:1 åˆ° 8:1
- input_len: åŒ…å«è¶³å¤Ÿå†å²ä¿¡æ¯ï¼ˆ1600-3000æ­¥ï¼‰
- output_len: å®é™…éœ€è¦é¢„æµ‹çš„é•¿åº¦ï¼ˆ400-1000æ­¥ï¼‰

### Q4: è®­ç»ƒå¤šå°‘ä¸ªepochåˆé€‚ï¼Ÿ
A: ä½¿ç”¨æ—©åœæœºåˆ¶ï¼Œé€šå¸¸20-50ä¸ªepochè¶³å¤Ÿã€‚å¦‚æœåœ¨å‰10ä¸ªepochå°±è§¦å‘æ—©åœï¼Œè¯´æ˜æ¨¡å‹å¤ªå¤æ‚ã€‚

### Q5: å¦‚ä½•åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´å¤šæ•°æ®ï¼Ÿ
A: å¦‚æœç”¨æœ€ç®€å•çš„æ¨¡å‹ï¼ˆd_model=32ï¼‰ä»ç„¶è¿‡æ‹Ÿåˆï¼Œè¯´æ˜æ•°æ®é‡ä¸è¶³ã€‚

---

## ğŸ¯ å¿«é€Ÿå†³ç­–æ ‘

```
è®­ç»ƒå®Œæˆåï¼Œè§‚å¯Ÿæ—¥å¿—ï¼š

è®­ç»ƒ/éªŒè¯æŸå¤±å·®è· > 0.3ï¼Ÿ
  â””â”€ æ˜¯ â†’ è¿‡æ‹Ÿåˆ â†’ é™ä½å¤æ‚åº¦ or å¢åŠ dropout
  â””â”€ å¦ â†’ ç»§ç»­

éªŒè¯æŸå¤± > 0.5ï¼Ÿ
  â””â”€ æ˜¯ â†’ æ£€æŸ¥æ˜¯å¦æ¬ æ‹Ÿåˆ
       â””â”€ è®­ç»ƒæŸå¤±ä¹Ÿé«˜ï¼Ÿ
            â””â”€ æ˜¯ â†’ æ¬ æ‹Ÿåˆ â†’ å¢åŠ å¤æ‚åº¦
            â””â”€ å¦ â†’ è¿‡æ‹Ÿåˆ â†’ é™ä½å¤æ‚åº¦
  â””â”€ å¦ â†’ æ•ˆæœä¸é”™ï¼

éªŒè¯æŸå¤±æ ‡å‡†å·® > 0.3ï¼Ÿ
  â””â”€ æ˜¯ â†’ ä¸ç¨³å®š â†’ å¢åŠ batch_size or é™ä½å­¦ä¹ ç‡
  â””â”€ å¦ â†’ ç»§ç»­

æµ‹è¯•æŸå¤± < 0.4ï¼Ÿ
  â””â”€ æ˜¯ â†’ æˆåŠŸï¼ğŸ‰
  â””â”€ å¦ â†’ ç»§ç»­ä¼˜åŒ–
```

---

**æœ€åæ›´æ–°ï¼š** 2025-10-13
**ç‰ˆæœ¬ï¼š** v1.0

