# 训练方法对比：旧方法 vs 新方法（滑动窗口）

## 📊 核心差异总结

| 特性 | 旧方法（多比例分割） | 新方法（滑动窗口） |
|------|---------------------|-------------------|
| **输入长度处理** | 动态长度，需要填充/截断 | 固定长度，无填充/截断 |
| **采样策略** | 按比例分割 (10%-90%) | 滑动窗口固定步长 |
| **参数含义** | 模糊（seq_len是"最大长度"） | 清晰（input_len是"固定输入长度"） |
| **训练测试一致性** | 不一致（训练用分割，测试可变） | 完全一致 |
| **样本数量** | 每井固定9个 | 取决于井长度和步长 |

---

## 🔄 旧方法详解

### 数据采样机制

```python
# 硬编码的分割比例
split_ratios = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

# 对一口4000步的井：
# 10%分割: 输入=400步 → 填充到640步 (前240步为0)
# 20%分割: 输入=800步 → 截断到640步 (只保留后640步)
# 50%分割: 输入=2000步 → 截断到640步
# 80%分割: 输入=3200步 → 截断到640步
# ...

# 所有输出固定为160步
```

### 问题分析

1. **早期比例效果差**（10%-30%）
   - 大量零填充，信息不足
   - 模型学到的主要是"如何处理零"

2. **后期比例丢失信息**（60%-90%）
   - 长输入被截断，只保留最近640步
   - 无法利用更早的历史信息

3. **参数含义混淆**
   ```bash
   --total_length 800 --input_ratio 0.8
   # 计算得到 seq_len=640
   # 但实际上：
   # - 训练时输入长度从400到3600不等（然后被填充/截断到640）
   # - seq_len实际上是"模型能处理的最大输入长度"
   # - 不是"实际使用的输入长度"
   ```

4. **训练测试不一致**
   - 训练：使用9个固定比例分割点
   - 测试：可以使用任意比例
   - 两者的数据分布可能不同

### 旧方法的训练命令

```bash
python scripts/train_8_2_ratio.py \
  --model_id wellmix_8_2_800 \
  --total_length 800 \
  --input_ratio 0.8 \
  --output_ratio 0.2 \
  --train_epochs 100
```

**实际发生的事情**：
- 计算 seq_len = 800 * 0.8 = 640
- 计算 pred_len = 800 * 0.2 = 160
- 但训练时使用9个分割比例，产生各种不同长度的输入
- 所有输入都被调整到640步（填充或截断）

---

## ✨ 新方法详解

### 数据采样机制

```python
# 滑动窗口参数
input_len = 640   # 固定输入长度
output_len = 160  # 固定输出长度
step_len = 160    # 滑动步长

# 对一口4000步的井：
# 窗口1: input=[0:640], output=[640:800]
# 窗口2: input=[160:800], output=[800:960]
# 窗口3: input=[320:960], output=[960:1120]
# ...
# 窗口N: input=[3680:4320] - 超出范围，丢弃

# 生成约 (4000 - 800) / 160 + 1 ≈ 21 个窗口
```

### 优势

1. **输入长度完全固定**
   - 所有样本的输入都是640步
   - 无填充，无截断
   - 模型看到的都是真实数据

2. **参数含义清晰**
   ```bash
   --input_len 640    # 就是640步输入
   --output_len 160   # 就是160步输出
   --step_len 160     # 每次滑动160步
   ```
   没有任何歧义！

3. **训练测试完全一致**
   - 训练集、验证集、测试集使用相同的滑动窗口策略
   - 唯一区别是井的划分（70% / 10% / 20%）
   - 数据分布一致

4. **样本数量可控**
   - 通过调整step_len控制样本密度
   - step_len = output_len: 无重叠（标准）
   - step_len < output_len: 有重叠（数据增强）
   - step_len > output_len: 有间隙（减少冗余）

5. **更好地利用长序列**
   - 长井可以生成更多窗口
   - 每个窗口都是独立的有效样本
   - 不会丢失早期历史信息

### 新方法的训练命令

```bash
python scripts/train_sliding_window.py \
  --model_id wellmix_sliding_640_160 \
  --input_len 640 \
  --output_len 160 \
  --step_len 160 \
  --train_epochs 100
```

**实际发生的事情**：
- 每口井按input_len=640, output_len=160, step_len=160生成窗口
- 所有窗口的输入长度都是精确的640步（无填充/截断）
- 所有窗口的输出长度都是精确的160步
- 训练、验证、测试使用相同策略

---

## 🔢 样本数量对比

假设有100口井，平均长度3500步：

### 旧方法
```
训练集（80口井）：
  - 每井9个样本（9个分割比例）
  - 总样本数：80 × 9 = 720

测试集（20口井）：
  - 每井9个样本
  - 总样本数：20 × 9 = 180
```

### 新方法（step_len=160）
```
训练集（70口井）：
  - 每井约 (3500-800)/160 ≈ 17 个窗口
  - 总样本数：70 × 17 ≈ 1190

验证集（10口井）：
  - 总样本数：10 × 17 ≈ 170

测试集（20口井）：
  - 总样本数：20 × 17 ≈ 340
```

**结论**：新方法生成的样本数更多，且所有样本质量一致（无填充）。

---

## 📈 性能预期

### 旧方法的典型表现
- 早期比例（10%-40%）：效果差，MAPE > 100%
- 中期比例（50%-70%）：效果中等
- 后期比例（80%-90%）：效果较好（如果有足够历史数据）

### 新方法的预期表现
- 所有窗口表现应该更一致
- 不会因为填充/截断导致的人为差异
- 模型学到的是纯粹的序列模式，而不是"如何处理填充"

---

## 🎯 使用建议

### 何时使用旧方法？
如果你需要：
- 在不同生命周期阶段测试模型（早期/中期/后期）
- 特意研究零填充对模型的影响
- 与之前的实验结果保持一致

### 何时使用新方法？
**推荐所有新实验使用新方法**，因为：
- 参数含义清晰，易于理解和调整
- 训练测试一致，评估更可靠
- 充分利用数据，无信息损失
- 更符合时间序列预测的标准做法

---

## 🔄 迁移指南

如果你想从旧方法切换到新方法：

### 步骤1：确定参数对应关系

旧参数：
```bash
--total_length 800
--input_ratio 0.8
--output_ratio 0.2
# 计算得到: seq_len=640, pred_len=160
```

新参数：
```bash
--input_len 640
--output_len 160
--step_len 160  # 推荐从output_len开始
```

### 步骤2：重新训练

```bash
# 旧命令
python scripts/train_8_2_ratio.py \
  --model_id wellmix_old \
  --total_length 800 \
  --input_ratio 0.8 \
  --output_ratio 0.2 \
  --train_epochs 100

# 对应的新命令
python scripts/train_sliding_window.py \
  --model_id wellmix_new \
  --input_len 640 \
  --output_len 160 \
  --step_len 160 \
  --train_epochs 100
```

### 步骤3：测试

```bash
# 旧命令（测试多个比例）
python scripts/test_and_visualize.py \
  --model_id wellmix_old \
  --ratios 10,20,30,40,50,60,70,80,90

# 新命令（测试所有滑动窗口）
python scripts/test_sliding_window.py \
  --model_id wellmix_new \
  --max_wells 10
```

### 步骤4：对比结果

新方法应该在以下方面表现更好：
- 整体平均指标（MAE/RMSE/MAPE）
- 不同窗口之间的一致性
- 训练稳定性（loss曲线更平滑）

---

## 📚 相关文件

### 旧方法
- 训练脚本：`scripts/train_8_2_ratio.py`
- 测试脚本：`scripts/test_and_visualize.py`
- 数据加载器：`data_provider/data_loader.py` (旧版本)

### 新方法
- 训练脚本：`scripts/train_sliding_window.py`
- 测试脚本：`scripts/test_sliding_window.py`
- 数据加载器：`data_provider/data_loader.py` (新版本，支持step_len参数)
- 使用指南：`SLIDING_WINDOW_GUIDE.md`

---

## ❓ 常见问题

### Q: 新旧方法可以共存吗？
A: 可以。两种方法使用不同的训练脚本，只要model_id不同即可。

### Q: 旧模型可以用新测试脚本测试吗？
A: 不建议。旧模型是在填充/截断数据上训练的，用新方法测试可能表现不佳。

### Q: 新方法训练会更慢吗？
A: 可能略慢（因为样本数更多），但可以通过增大step_len来控制。

### Q: 如何选择step_len？
A: 
- 标准训练：step_len = output_len（无重叠）
- 数据增强：step_len = output_len / 2（50%重叠）
- 快速实验：step_len = output_len * 2（有间隙）

---

## 🎓 总结

新的滑动窗口方法是对旧方法的全面改进：
- ✅ 参数含义清晰
- ✅ 训练测试一致
- ✅ 无数据损失
- ✅ 更符合标准实践
- ✅ 性能可预期

**强烈推荐所有新实验使用新方法！** 🚀

