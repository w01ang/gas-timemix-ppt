╔════════════════════════════════════════════════════════════════════════════╗
║                    🚨 NaN损失快速修复指南                                   ║
╚════════════════════════════════════════════════════════════════════════════╝

【问题】训练时 valid loss 显示为 NaN

【原因】90%的情况是学习率过高导致梯度爆炸

【解决】已自动添加梯度裁剪，直接运行下面命令即可！

╔════════════════════════════════════════════════════════════════════════════╗
║ ⚡ 方案1: 降低学习率 (立即尝试!) ⭐⭐⭐⭐⭐                              ║
╚════════════════════════════════════════════════════════════════════════════╝

python scripts/train_sliding_window.py \
  --model_id slide_fix_nan_lr1e5 \
  --input_len 3000 \
  --output_len 1000 \
  --step_len 50 \
  --batch_size 16 \
  --learning_rate 1e-5 \
  --train_epochs 60 \
  --use_gpu

关键改动: --learning_rate 1e-5 (从1e-4降低10倍)
成功率: 90%

╔════════════════════════════════════════════════════════════════════════════╗
║ 🛡️  方案2: 保守配置 (如果方案1还NaN) ⭐⭐⭐⭐                           ║
╚════════════════════════════════════════════════════════════════════════════╝

python scripts/train_sliding_window.py \
  --model_id slide_ultra_stable \
  --input_len 3000 \
  --output_len 1000 \
  --step_len 50 \
  --batch_size 32 \
  --d_model 128 --n_heads 8 --e_layers 3 \
  --d_ff 512 --dropout 0.2 \
  --learning_rate 5e-5 \
  --train_epochs 60 \
  --use_gpu

关键改动: 
  • batch_size 32 (更稳定)
  • d_model 128 (降低复杂度)
  • learning_rate 5e-5

╔════════════════════════════════════════════════════════════════════════════╗
║ 🔒 方案3: 极保守 (最后手段) ⭐⭐⭐                                       ║
╚════════════════════════════════════════════════════════════════════════════╝

python scripts/train_sliding_window.py \
  --model_id slide_super_safe \
  --input_len 3000 \
  --output_len 1000 \
  --step_len 100 \
  --batch_size 32 \
  --d_model 64 --n_heads 4 --e_layers 2 \
  --d_ff 256 --dropout 0.3 \
  --learning_rate 5e-6 \
  --train_epochs 80 \
  --use_gpu

关键改动:
  • d_model 64 (最小模型)
  • learning_rate 5e-6 (极低)
  • 梯度裁剪已启用

╔════════════════════════════════════════════════════════════════════════════╗
║ 🔍 如何判断修复成功?                                                       ║
╚════════════════════════════════════════════════════════════════════════════╝

训练开始后观察前5个epoch:

✅ 修复成功:
  Epoch 1: Train=1.5, Vali=1.3, Test=1.4
  Epoch 2: Train=1.2, Vali=1.1, Test=1.2
  Epoch 3: Train=1.0, Vali=0.9, Test=1.0
  → 损失平滑下降，无NaN

❌ 仍有问题:
  Epoch 1: Train=5.2, Vali=NaN
  → 立即停止，尝试下一个方案

╔════════════════════════════════════════════════════════════════════════════╗
║ 💡 关键要点                                                                ║
╚════════════════════════════════════════════════════════════════════════════╝

1. 梯度裁剪已自动添加
   位置: scripts/train_sliding_window.py 第167行
   无需手动修改

2. 优先尝试方案1
   90%的NaN都是学习率过高

3. 依次尝试
   方案1 → 方案2 → 方案3

4. 观察首轮损失
   如果Epoch 1就NaN，说明学习率还是太高

╔════════════════════════════════════════════════════════════════════════════╗
║ 📚 更多信息                                                                ║
╚════════════════════════════════════════════════════════════════════════════╝

完整文档: FIX_NAN_LOSS.md
数据检查脚本: scripts/check_data_for_nan.py

╔════════════════════════════════════════════════════════════════════════════╗
║ 🚀 立即行动: 复制方案1命令运行!                                            ║
╚════════════════════════════════════════════════════════════════════════════╝
