#!/usr/bin/env python3
"""
æ»‘åŠ¨çª—å£æ¨¡å‹æµ‹è¯•ä¸å¯è§†åŒ–è„šæœ¬
ä¸train_sliding_window.pyé…å¥—ä½¿ç”¨
"""

import os
import sys
import argparse
import json
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast
from argparse import Namespace

def load_experiment_config(model_id):
    """åŠ è½½å®éªŒé…ç½®"""
    config_path = f"experiments/{model_id}/config.json"
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    print(f"âœ… å·²åŠ è½½å®éªŒé…ç½®: {config_path}")
    print(f"   è¾“å…¥é•¿åº¦: {config['input_len']}")
    print(f"   è¾“å‡ºé•¿åº¦: {config['output_len']}")
    print(f"   æ»‘åŠ¨æ­¥é•¿: {config['step_len']}")
    
    return config

def create_test_args(config):
    """æ ¹æ®é…ç½®åˆ›å»ºæµ‹è¯•å‚æ•°"""
    args = Namespace(
        task_name='long_term_forecast',
        is_training=0,
        model_id=config['model_id'],
        model='TimeMixer',
        data='WELLS',
        root_path=config.get('root_path', '/Users/wangjr/Documents/yk/timemixer/data'),
        data_path=config.get('data_path', 'preprocessed_daily_gas_by_well.csv'),
        features='S',
        target='OT',
        freq='d',
        checkpoints='./checkpoints/',
        seq_len=config['input_len'],
        label_len=config['output_len'],
        pred_len=config['output_len'],
        step_len=config['step_len'],
        seasonal_patterns='Monthly',
        inverse=True,
        top_k=5,
        num_kernels=6,
        enc_in=1,
        dec_in=1,
        c_out=1,
        d_model=config['d_model'],
        n_heads=config['n_heads'],
        e_layers=config['e_layers'],
        d_layers=config['d_layers'],
        d_ff=config['d_ff'],
        moving_avg=999,  # æ”¹ä¸º999ï¼ˆå¥‡æ•°ï¼‰ï¼Œé€‚åˆ3000æ­¥è¾“å…¥çš„å­£èŠ‚æ€§åˆ†è§£
        factor=1,
        distil=True,
        dropout=0.1,
        embed='timeF',
        activation='gelu',
        output_attention=False,
        channel_independence=1,
        decomp_method='moving_avg',
        use_norm=1,
        down_sampling_layers=2,  # æ”¹ä¸º2å±‚ï¼Œäº§ç”Ÿ3ä¸ªå°ºåº¦(3000/1500/750)
        down_sampling_window=2,
        down_sampling_method='avg',
        use_future_temporal_feature=0,
        mask_rate=0.125,
        anomaly_ratio=0.25,
        num_workers=0,
        itr=1,
        train_epochs=config['train_epochs'],
        batch_size=1,  # æµ‹è¯•æ—¶batch_size=1
        patience=config['patience'],
        learning_rate=config['learning_rate'],
        des=config.get('description', 'Test'),
        loss='MSE',
        drop_last=False,
        lradj='TST',
        pct_start=0.2,
        use_amp=False,
        comment=config.get('comment', 'test'),
        use_gpu=config.get('use_gpu', False),
        gpu=0,
        use_multi_gpu=False,
        devices='0,1',
        p_hidden_dims=[128, 128],
        p_hidden_layers=2
    )
    return args

def predict_well_sliding_windows(exp, well_data, input_len, output_len, step_len):
    """
    å¯¹å•å£äº•ä½¿ç”¨æ»‘åŠ¨çª—å£è¿›è¡Œé¢„æµ‹
    
    è¿”å›: æ‰€æœ‰çª—å£çš„é¢„æµ‹ç»“æœåˆ—è¡¨
    [(start_idx, true_output, predicted_output), ...]
    """
    model = exp.model
    device = next(model.parameters()).device
    model.eval()
    
    well_length = len(well_data)
    min_window_size = input_len + output_len
    results = []
    
    # ç”Ÿæˆæ»‘åŠ¨çª—å£
    num_windows = (well_length - min_window_size) // step_len + 1
    
    with torch.no_grad():
        for window_idx in range(num_windows):
            start_idx = window_idx * step_len
            end_idx = start_idx + input_len + output_len
            
            if end_idx > well_length:
                break
            
            # æå–è¾“å…¥å’ŒçœŸå®è¾“å‡º
            input_seq = well_data[start_idx:start_idx + input_len]
            true_output = well_data[start_idx + input_len:end_idx]
            
            # æ ‡å‡†åŒ–
            input_normalized = exp.test_data.dataset._transform(input_seq).reshape(-1, 1)
            
            # æ„é€ æ¨¡å‹è¾“å…¥
            x_enc = torch.from_numpy(input_normalized).float().unsqueeze(0).to(device)
            x_mark_enc = torch.zeros((1, input_len, 3)).to(device)
            y_mark = torch.zeros((1, output_len, 3)).to(device)
            
            # è§£ç å™¨è¾“å…¥ï¼ˆä½¿ç”¨éƒ¨åˆ†çœŸå®å€¼+é›¶å¡«å……ï¼‰
            dec_inp = torch.zeros((1, output_len, 1)).to(device)
            
            # é¢„æµ‹
            outputs = model(x_enc, x_mark_enc, dec_inp, y_mark)
            pred = outputs.detach().cpu().numpy()[0, :, 0]
            
            # åæ ‡å‡†åŒ–
            pred = exp.test_data.dataset.inverse_transform(pred)
            
            results.append({
                'start_idx': start_idx,
                'input_end_idx': start_idx + input_len,
                'end_idx': end_idx,
                'true_output': true_output,
                'predicted_output': pred
            })
    
    return results

def visualize_well_predictions(well_idx, well_data, predictions, input_len, output_len, 
                                output_dir, model_id):
    """
    å¯è§†åŒ–å•å£äº•çš„æ‰€æœ‰çª—å£é¢„æµ‹ç»“æœ
    """
    fig, ax = plt.subplots(figsize=(16, 6))
    
    well_length = len(well_data)
    x_full = np.arange(well_length)
    
    # ç»˜åˆ¶å®Œæ•´äº•åºåˆ—ï¼ˆæµ…ç°è‰²èƒŒæ™¯ï¼‰
    ax.plot(x_full, well_data, color='lightgray', linewidth=1, alpha=0.5, 
            label='å®Œæ•´åºåˆ—', zorder=1)
    
    # ç»˜åˆ¶æ¯ä¸ªçª—å£çš„é¢„æµ‹
    colors = plt.cm.rainbow(np.linspace(0, 1, len(predictions)))
    
    for i, (pred_info, color) in enumerate(zip(predictions, colors)):
        start_idx = pred_info['start_idx']
        input_end = pred_info['input_end_idx']
        end_idx = pred_info['end_idx']
        
        # è¾“å…¥æ®µï¼ˆè“è‰²ï¼‰
        ax.plot(x_full[start_idx:input_end], well_data[start_idx:input_end], 
                color='blue', linewidth=1.5, alpha=0.3, zorder=2)
        
        # çœŸå®è¾“å‡ºï¼ˆç»¿è‰²ï¼‰
        ax.plot(x_full[input_end:end_idx], pred_info['true_output'], 
                color='green', linewidth=2, alpha=0.6, zorder=3)
        
        # é¢„æµ‹è¾“å‡ºï¼ˆæ©™è‰²ï¼‰
        ax.plot(x_full[input_end:end_idx], pred_info['predicted_output'], 
                color='orange', linewidth=2, alpha=0.6, linestyle='--', zorder=4)
        
        # æ ‡è®°çª—å£è¾¹ç•Œ
        if i == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªçª—å£æ·»åŠ å›¾ä¾‹
            ax.axvline(x=input_end, color='red', linestyle='--', alpha=0.5, 
                      linewidth=1, label='é¢„æµ‹èµ·ç‚¹', zorder=5)
        else:
            ax.axvline(x=input_end, color='red', linestyle='--', alpha=0.3, 
                      linewidth=0.5, zorder=5)
    
    ax.set_xlabel('æ—¶é—´æ­¥', fontsize=12)
    ax.set_ylabel('æ—¥äº§é‡', fontsize=12)
    ax.set_title(f'äº• {well_idx} - æ»‘åŠ¨çª—å£é¢„æµ‹ ({len(predictions)}ä¸ªçª—å£)', fontsize=14)
    ax.legend(loc='upper right')
    ax.grid(True, alpha=0.3)
    ax.set_xlim(0, well_length)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    output_path = f"{output_dir}/well_{well_idx}_sliding_windows.pdf"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"   å·²ä¿å­˜: {output_path}")

def calculate_metrics(true_values, predicted_values):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    mae = np.mean(np.abs(true_values - predicted_values))
    rmse = np.sqrt(np.mean((true_values - predicted_values) ** 2))
    mape = np.mean(np.abs((true_values - predicted_values) / (true_values + 1e-8))) * 100
    
    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}

def main():
    parser = argparse.ArgumentParser(description='æ»‘åŠ¨çª—å£æ¨¡å‹æµ‹è¯•ä¸å¯è§†åŒ–')
    parser.add_argument('--model_id', type=str, required=True, help='å®éªŒID')
    parser.add_argument('--output_dir', type=str, default=None, help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: test_results/<model_id>ï¼‰')
    parser.add_argument('--max_wells', type=int, default=None, help='æœ€å¤šæµ‹è¯•å¤šå°‘å£äº•ï¼ˆé»˜è®¤: å…¨éƒ¨ï¼‰')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    print(f"ğŸ” åŠ è½½å®éªŒé…ç½®...")
    config = load_experiment_config(args.model_id)
    
    # åˆ›å»ºæµ‹è¯•å‚æ•°
    test_args = create_test_args(config)
    
    # åˆ›å»ºå®éªŒå¯¹è±¡
    print(f"\nğŸ“Š åˆå§‹åŒ–å®éªŒ...")
    exp = Exp_Long_Term_Forecast(test_args)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    _, exp.test_data = exp._get_data(flag='test')
    
    # åŠ è½½æ¨¡å‹
    checkpoint_path = f"./checkpoints/{args.model_id}/checkpoint.pth"
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
    
    exp.model.load_state_dict(torch.load(checkpoint_path, map_location=exp.device))
    print(f"âœ… å·²åŠ è½½æ¨¡å‹: {checkpoint_path}")
    
    # å‡†å¤‡è¾“å‡ºç›®å½•
    if args.output_dir is None:
        args.output_dir = f"test_results/{args.model_id}"
    os.makedirs(args.output_dir, exist_ok=True)
    
    # è·å–æµ‹è¯•æ•°æ®
    print(f"\nğŸ§ª å¼€å§‹æµ‹è¯•...")
    test_wells = exp.test_data.dataset.well_series
    
    input_len = config['input_len']
    output_len = config['output_len']
    step_len = config['step_len']
    
    print(f"   æµ‹è¯•é›†äº•æ•°: {len(test_wells)}")
    print(f"   è¾“å…¥é•¿åº¦: {input_len}, è¾“å‡ºé•¿åº¦: {output_len}, æ­¥é•¿: {step_len}")
    
    # æµ‹è¯•æ¯å£äº•
    all_results = []
    max_wells = args.max_wells if args.max_wells else len(test_wells)
    
    for well_idx, well_data in enumerate(test_wells[:max_wells]):
        print(f"\nğŸ”¹ æµ‹è¯•äº• {well_idx} (é•¿åº¦: {len(well_data)})...")
        
        # é¢„æµ‹æ‰€æœ‰çª—å£
        predictions = predict_well_sliding_windows(
            exp, well_data, input_len, output_len, step_len
        )
        
        if len(predictions) == 0:
            print(f"   âš ï¸  äº• {well_idx} é•¿åº¦ä¸è¶³ï¼Œè·³è¿‡")
            continue
        
        print(f"   ç”Ÿæˆäº† {len(predictions)} ä¸ªçª—å£é¢„æµ‹")
        
        # è®¡ç®—æ¯ä¸ªçª—å£çš„æŒ‡æ ‡
        for pred_info in predictions:
            metrics = calculate_metrics(
                pred_info['true_output'], 
                pred_info['predicted_output']
            )
            all_results.append({
                'well_idx': well_idx,
                'start_idx': pred_info['start_idx'],
                'MAE': metrics['MAE'],
                'RMSE': metrics['RMSE'],
                'MAPE': metrics['MAPE']
            })
        
        # å¯è§†åŒ–
        visualize_well_predictions(
            well_idx, well_data, predictions, 
            input_len, output_len, args.output_dir, args.model_id
        )
    
    # ä¿å­˜ç»“æœ
    if all_results:
        results_df = pd.DataFrame(all_results)
        results_path = f"{args.output_dir}/results.csv"
        results_df.to_csv(results_path, index=False)
        print(f"\nğŸ“„ ç»“æœå·²ä¿å­˜: {results_path}")
        
        # ç»Ÿè®¡æ±‡æ€»
        print(f"\nğŸ“Š æ€»ä½“è¯„ä¼°æŒ‡æ ‡:")
        print(f"   å¹³å‡ MAE: {results_df['MAE'].mean():.4f}")
        print(f"   å¹³å‡ RMSE: {results_df['RMSE'].mean():.4f}")
        print(f"   å¹³å‡ MAPE: {results_df['MAPE'].mean():.2f}%")
        
        # æŒ‰äº•ç»Ÿè®¡
        well_stats = results_df.groupby('well_idx').agg({
            'MAE': 'mean',
            'RMSE': 'mean',
            'MAPE': 'mean'
        }).reset_index()
        
        well_stats_path = f"{args.output_dir}/well_statistics.csv"
        well_stats.to_csv(well_stats_path, index=False)
        print(f"   äº•ç»Ÿè®¡å·²ä¿å­˜: {well_stats_path}")
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {args.output_dir}")

if __name__ == "__main__":
    main()

