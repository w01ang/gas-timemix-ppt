#!/usr/bin/env python3
"""
é€’å½’é¢„æµ‹æµ‹è¯•ä¸å¯è§†åŒ–è„šæœ¬
ä½¿ç”¨æ»‘åŠ¨çª—å£é€’å½’é¢„æµ‹ï¼šæ¯æ¬¡é¢„æµ‹åï¼Œå°†é¢„æµ‹ç»“æœæ‹¼æ¥åˆ°è¾“å…¥åºåˆ—ï¼Œç„¶åç»§ç»­é¢„æµ‹
"""

import os
import sys
import argparse
import json
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast
from argparse import Namespace

def load_experiment_config(model_id):
    """åŠ è½½å®éªŒé…ç½®"""
    config_path = f"experiments/{model_id}/config.json"
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    print(f"âœ… å·²åŠ è½½å®éªŒé…ç½®: {config_path}")
    print(f"   è¾“å…¥é•¿åº¦: {config['input_len']}")
    print(f"   è¾“å‡ºé•¿åº¦: {config['output_len']}")
    
    return config

def create_test_args(config):
    """æ ¹æ®é…ç½®åˆ›å»ºæµ‹è¯•å‚æ•°"""
    args = Namespace(
        task_name='long_term_forecast',
        is_training=0,
        model_id=config['model_id'],
        model='TimeMixer',
        data='WELLS',
        root_path=config.get('root_path', '/Users/wangjr/Documents/yk/timemixer/data'),
        data_path=config.get('data_path', 'preprocessed_daily_gas_by_well.csv'),
        features='S',
        target='OT',
        freq='d',
        checkpoints='./checkpoints/',
        seq_len=config['input_len'],
        label_len=config['output_len'],
        pred_len=config['output_len'],
        step_len=config.get('step_len', config['output_len']),
        seasonal_patterns='Monthly',
        inverse=True,
        top_k=5,
        num_kernels=6,
        enc_in=1,
        dec_in=1,
        c_out=1,
        d_model=config['d_model'],
        n_heads=config['n_heads'],
        e_layers=config['e_layers'],
        d_layers=config['d_layers'],
        d_ff=config['d_ff'],
        moving_avg=999,  # æ”¹ä¸º999ï¼ˆå¥‡æ•°ï¼‰ï¼Œé€‚åˆ3000æ­¥è¾“å…¥çš„å­£èŠ‚æ€§åˆ†è§£
        factor=1,
        distil=True,
        dropout=0.1,
        embed='timeF',
        activation='gelu',
        output_attention=False,
        channel_independence=1,
        decomp_method='moving_avg',
        use_norm=1,
        down_sampling_layers=2,  # æ”¹ä¸º2å±‚ï¼Œäº§ç”Ÿ3ä¸ªå°ºåº¦(3000/1500/750)
        down_sampling_window=2,
        down_sampling_method='avg',
        use_future_temporal_feature=0,
        mask_rate=0.125,
        anomaly_ratio=0.25,
        num_workers=0,
        itr=1,
        train_epochs=config['train_epochs'],
        batch_size=1,
        patience=config['patience'],
        learning_rate=config['learning_rate'],
        des=config.get('description', 'Test'),
        loss='MSE',
        drop_last=False,
        lradj='TST',
        pct_start=0.2,
        use_amp=False,
        comment=config.get('comment', 'test'),
        use_gpu=config.get('use_gpu', False),
        gpu=0,
        use_multi_gpu=False,
        devices='0,1',
        p_hidden_dims=[128, 128],
        p_hidden_layers=2
    )
    return args

def predict_one_step(model, input_seq, input_len, output_len, scaler, device):
    """
    å•æ¬¡é¢„æµ‹
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        input_seq: è¾“å…¥åºåˆ—ï¼ˆåŸå§‹å€¼ï¼‰
        input_len: è¾“å…¥é•¿åº¦
        output_len: è¾“å‡ºé•¿åº¦
        scaler: æ•°æ®æ ‡å‡†åŒ–å™¨
        device: è®¡ç®—è®¾å¤‡
    
    Returns:
        é¢„æµ‹ç»“æœï¼ˆåŸå§‹å€¼ï¼‰
    """
    # ç¡®ä¿è¾“å…¥é•¿åº¦æ­£ç¡®
    if len(input_seq) > input_len:
        input_seq = input_seq[-input_len:]
    elif len(input_seq) < input_len:
        # å¦‚æœè¾“å…¥ä¸è¶³ï¼Œç”¨é›¶å¡«å……
        pad = np.zeros((input_len - len(input_seq),), dtype=np.float32)
        input_seq = np.concatenate([pad, input_seq])
    
    # æ ‡å‡†åŒ–
    input_normalized = scaler._transform(input_seq).reshape(-1, 1)
    
    # æ„é€ æ¨¡å‹è¾“å…¥
    x_enc = torch.from_numpy(input_normalized).float().unsqueeze(0).to(device)
    x_mark_enc = torch.zeros((1, input_len, 3)).to(device)
    y_mark = torch.zeros((1, output_len, 3)).to(device)
    dec_inp = torch.zeros((1, output_len, 1)).to(device)
    
    # é¢„æµ‹
    with torch.no_grad():
        outputs = model(x_enc, x_mark_enc, dec_inp, y_mark)
        pred = outputs.detach().cpu().numpy()[0, :, 0]
    
    # åæ ‡å‡†åŒ–
    pred = scaler.inverse_transform(pred)
    
    return pred

def recursive_predict_well(exp, well_data, input_len, output_len, max_steps=None):
    """
    å¯¹å•å£äº•è¿›è¡Œé€’å½’é¢„æµ‹
    
    Args:
        exp: å®éªŒå¯¹è±¡
        well_data: äº•çš„å®Œæ•´åºåˆ—
        input_len: è¾“å…¥é•¿åº¦
        output_len: æ¯æ¬¡é¢„æµ‹é•¿åº¦
        max_steps: æœ€å¤§é¢„æµ‹æ­¥æ•°ï¼ˆNoneåˆ™é¢„æµ‹åˆ°åŸå§‹åºåˆ—é•¿åº¦ï¼‰
    
    Returns:
        dict: åŒ…å«é¢„æµ‹å†å²çš„å­—å…¸
    """
    model = exp.model
    device = next(model.parameters()).device
    scaler = exp.test_data.dataset
    model.eval()
    
    well_length = len(well_data)
    
    # åˆå§‹è¾“å…¥ï¼šäº•çš„å‰input_lenæ­¥
    current_sequence = well_data[:input_len].copy()
    
    # å­˜å‚¨é¢„æµ‹å†å²
    prediction_history = []
    
    # è®¡ç®—éœ€è¦é¢„æµ‹çš„æ¬¡æ•°
    if max_steps is None:
        remaining_length = well_length - input_len
        num_predictions = (remaining_length + output_len - 1) // output_len
    else:
        num_predictions = max_steps
    
    print(f"      åˆå§‹è¾“å…¥é•¿åº¦: {len(current_sequence)}")
    print(f"      ç›®æ ‡é•¿åº¦: {well_length}")
    print(f"      éœ€è¦é¢„æµ‹: {num_predictions} æ¬¡")
    
    for step in range(num_predictions):
        # è·å–å½“å‰è¾“å…¥ï¼ˆæœ€åinput_lenæ­¥ï¼‰
        if len(current_sequence) >= input_len:
            current_input = current_sequence[-input_len:]
        else:
            current_input = current_sequence
        
        # é¢„æµ‹ä¸‹ä¸€ä¸ªoutput_lenæ­¥
        pred = predict_one_step(
            model, current_input, input_len, output_len, scaler, device
        )
        
        # è®°å½•é¢„æµ‹
        pred_start_idx = len(current_sequence)
        pred_end_idx = pred_start_idx + output_len
        
        # è·å–çœŸå®å€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if pred_end_idx <= well_length:
            true_values = well_data[pred_start_idx:pred_end_idx]
        else:
            # è¶…å‡ºåŸå§‹åºåˆ—é•¿åº¦ï¼Œåªå–éƒ¨åˆ†çœŸå®å€¼
            true_values = well_data[pred_start_idx:well_length]
            pred = pred[:len(true_values)]  # æˆªæ–­é¢„æµ‹å€¼
        
        prediction_history.append({
            'step': step + 1,
            'pred_start_idx': pred_start_idx,
            'pred_end_idx': pred_start_idx + len(pred),
            'predicted': pred.copy(),
            'true': true_values.copy(),
            'input_start_idx': max(0, pred_start_idx - input_len),
            'input_end_idx': pred_start_idx
        })
        
        # å°†é¢„æµ‹ç»“æœæ‹¼æ¥åˆ°å½“å‰åºåˆ—
        current_sequence = np.concatenate([current_sequence, pred])
        
        # å¦‚æœå·²ç»è¾¾åˆ°æˆ–è¶…è¿‡ç›®æ ‡é•¿åº¦ï¼Œåœæ­¢
        if len(current_sequence) >= well_length:
            break
    
    return {
        'well_length': well_length,
        'input_len': input_len,
        'output_len': output_len,
        'predictions': prediction_history,
        'final_sequence': current_sequence,
        'original_sequence': well_data
    }

def visualize_recursive_prediction(well_idx, result, output_dir, model_id):
    """
    å¯è§†åŒ–é€’å½’é¢„æµ‹ç»“æœ
    """
    fig, ax = plt.subplots(figsize=(20, 6))
    
    well_data = result['original_sequence']
    well_length = result['well_length']
    input_len = result['input_len']
    predictions = result['predictions']
    
    x_full = np.arange(well_length)
    
    # 1. ç»˜åˆ¶å®Œæ•´çœŸå®åºåˆ—ï¼ˆæµ…ç°è‰²èƒŒæ™¯ï¼‰
    ax.plot(x_full, well_data, color='lightgray', linewidth=1.5, alpha=0.6, 
            label='çœŸå®åºåˆ—ï¼ˆå®Œæ•´ï¼‰', zorder=1)
    
    # 2. ç»˜åˆ¶åˆå§‹è¾“å…¥æ®µï¼ˆæ·±è“è‰²ï¼‰
    ax.plot(x_full[:input_len], well_data[:input_len], 
            color='darkblue', linewidth=2.5, label='åˆå§‹è¾“å…¥æ®µ', zorder=3)
    
    # 3. æ ‡è®°åˆå§‹è¾“å…¥ç»“æŸç‚¹
    ax.axvline(x=input_len, color='blue', linestyle=':', alpha=0.7, 
              linewidth=2, label='åˆå§‹è¾“å…¥ç»ˆç‚¹', zorder=2)
    
    # 4. ç»˜åˆ¶æ¯æ¬¡é¢„æµ‹çš„ç»“æœ
    colors = plt.cm.rainbow(np.linspace(0, 1, len(predictions)))
    
    for i, (pred_info, color) in enumerate(zip(predictions, colors)):
        pred_start = pred_info['pred_start_idx']
        pred_end = pred_info['pred_end_idx']
        
        # é¢„æµ‹å€¼ï¼ˆè™šçº¿ï¼‰
        x_pred = np.arange(pred_start, pred_end)
        if i == 0:
            ax.plot(x_pred, pred_info['predicted'], 
                   color='orange', linewidth=2, linestyle='--', alpha=0.8,
                   label='é€’å½’é¢„æµ‹å€¼', zorder=4)
        else:
            ax.plot(x_pred, pred_info['predicted'], 
                   color='orange', linewidth=2, linestyle='--', alpha=0.8, zorder=4)
        
        # æ ‡è®°æ¯æ¬¡é¢„æµ‹çš„èµ·ç‚¹
        if i > 0:  # è·³è¿‡ç¬¬ä¸€æ¬¡ï¼ˆå·²ç»æœ‰åˆå§‹è¾“å…¥ç»ˆç‚¹æ ‡è®°ï¼‰
            ax.axvline(x=pred_start, color='red', linestyle='--', alpha=0.3, 
                      linewidth=0.8, zorder=2)
    
    # 5. æ·»åŠ å›¾ä¾‹å’Œæ ‡ç­¾
    ax.set_xlabel('æ—¶é—´æ­¥', fontsize=13, fontweight='bold')
    ax.set_ylabel('æ—¥äº§é‡', fontsize=13, fontweight='bold')
    ax.set_title(f'äº• {well_idx} - é€’å½’é¢„æµ‹ (å…±{len(predictions)}æ¬¡é¢„æµ‹ï¼Œæ¯æ¬¡{result["output_len"]}æ­¥)', 
                fontsize=15, fontweight='bold')
    ax.legend(loc='upper right', fontsize=11)
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.set_xlim(0, well_length)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    output_path = f"{output_dir}/well_{well_idx}_recursive_prediction.pdf"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"      å·²ä¿å­˜å¯è§†åŒ–: {output_path}")

def calculate_metrics(true_values, predicted_values):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    mae = np.mean(np.abs(true_values - predicted_values))
    rmse = np.sqrt(np.mean((true_values - predicted_values) ** 2))
    
    # é¿å…é™¤é›¶
    non_zero_mask = np.abs(true_values) > 1e-8
    if np.any(non_zero_mask):
        mape = np.mean(np.abs((true_values[non_zero_mask] - predicted_values[non_zero_mask]) 
                              / true_values[non_zero_mask])) * 100
    else:
        mape = 0.0
    
    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}

def main():
    parser = argparse.ArgumentParser(description='é€’å½’é¢„æµ‹æµ‹è¯•ä¸å¯è§†åŒ–')
    parser.add_argument('--model_id', type=str, required=True, help='å®éªŒID')
    parser.add_argument('--output_dir', type=str, default=None, 
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: test_results/<model_id>_recursiveï¼‰')
    parser.add_argument('--max_wells', type=int, default=None, 
                       help='æœ€å¤šæµ‹è¯•å¤šå°‘å£äº•ï¼ˆé»˜è®¤: å…¨éƒ¨ï¼‰')
    parser.add_argument('--max_steps', type=int, default=None, 
                       help='æ¯å£äº•æœ€å¤šé¢„æµ‹å¤šå°‘æ¬¡ï¼ˆé»˜è®¤: é¢„æµ‹åˆ°åŸå§‹åºåˆ—é•¿åº¦ï¼‰')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    print(f"ğŸ” åŠ è½½å®éªŒé…ç½®...")
    config = load_experiment_config(args.model_id)
    
    # åˆ›å»ºæµ‹è¯•å‚æ•°
    test_args = create_test_args(config)
    
    # åˆ›å»ºå®éªŒå¯¹è±¡
    print(f"\nğŸ“Š åˆå§‹åŒ–å®éªŒ...")
    exp = Exp_Long_Term_Forecast(test_args)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    _, exp.test_data = exp._get_data(flag='test')
    
    # åŠ è½½æ¨¡å‹
    checkpoint_path = f"./checkpoints/{args.model_id}/checkpoint.pth"
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
    
    exp.model.load_state_dict(torch.load(checkpoint_path, map_location=exp.device))
    print(f"âœ… å·²åŠ è½½æ¨¡å‹: {checkpoint_path}")
    
    # å‡†å¤‡è¾“å‡ºç›®å½•
    if args.output_dir is None:
        args.output_dir = f"test_results/{args.model_id}_recursive"
    os.makedirs(args.output_dir, exist_ok=True)
    
    # è·å–æµ‹è¯•æ•°æ®
    print(f"\nğŸ§ª å¼€å§‹é€’å½’é¢„æµ‹...")
    test_wells = exp.test_data.dataset.well_series
    
    input_len = config['input_len']
    output_len = config['output_len']
    
    print(f"   æµ‹è¯•é›†äº•æ•°: {len(test_wells)}")
    print(f"   è¾“å…¥é•¿åº¦: {input_len}")
    print(f"   æ¯æ¬¡é¢„æµ‹é•¿åº¦: {output_len}")
    print(f"   é¢„æµ‹ç­–ç•¥: é€’å½’é¢„æµ‹ï¼ˆæ¯æ¬¡é¢„æµ‹åæ‹¼æ¥åˆ°è¾“å…¥åºåˆ—ï¼‰")
    
    # æµ‹è¯•æ¯å£äº•
    all_results = []
    well_summaries = []
    max_wells = args.max_wells if args.max_wells else len(test_wells)
    
    for well_idx, well_data in enumerate(test_wells[:max_wells]):
        print(f"\nğŸ”¹ æµ‹è¯•äº• {well_idx} (é•¿åº¦: {len(well_data)})...")
        
        if len(well_data) <= input_len:
            print(f"      âš ï¸  äº• {well_idx} é•¿åº¦ä¸è¶³ï¼ˆéœ€è¦>{input_len}ï¼‰ï¼Œè·³è¿‡")
            continue
        
        # é€’å½’é¢„æµ‹
        result = recursive_predict_well(
            exp, well_data, input_len, output_len, max_steps=args.max_steps
        )
        
        # è®¡ç®—æ¯æ¬¡é¢„æµ‹çš„æŒ‡æ ‡
        step_metrics = []
        for pred_info in result['predictions']:
            metrics = calculate_metrics(pred_info['true'], pred_info['predicted'])
            step_metrics.append({
                'well_idx': well_idx,
                'step': pred_info['step'],
                'pred_start_idx': pred_info['pred_start_idx'],
                'pred_end_idx': pred_info['pred_end_idx'],
                'MAE': metrics['MAE'],
                'RMSE': metrics['RMSE'],
                'MAPE': metrics['MAPE']
            })
            all_results.append(step_metrics[-1])
        
        # è®¡ç®—æ•´ä½“æŒ‡æ ‡ï¼ˆæ‰€æœ‰é¢„æµ‹æ­¥åˆå¹¶ï¼‰
        all_pred = np.concatenate([p['predicted'] for p in result['predictions']])
        all_true = np.concatenate([p['true'] for p in result['predictions']])
        overall_metrics = calculate_metrics(all_true, all_pred)
        
        well_summaries.append({
            'well_idx': well_idx,
            'well_length': len(well_data),
            'num_predictions': len(result['predictions']),
            'total_pred_length': len(all_pred),
            'overall_MAE': overall_metrics['MAE'],
            'overall_RMSE': overall_metrics['RMSE'],
            'overall_MAPE': overall_metrics['MAPE']
        })
        
        print(f"      å®Œæˆ {len(result['predictions'])} æ¬¡é¢„æµ‹")
        print(f"      æ•´ä½“ MAE: {overall_metrics['MAE']:.2f}")
        print(f"      æ•´ä½“ RMSE: {overall_metrics['RMSE']:.2f}")
        print(f"      æ•´ä½“ MAPE: {overall_metrics['MAPE']:.2f}%")
        
        # å¯è§†åŒ–
        visualize_recursive_prediction(
            well_idx, result, args.output_dir, args.model_id
        )
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    if all_results:
        # ä¿å­˜æ¯æ­¥ç»“æœ
        results_df = pd.DataFrame(all_results)
        results_path = f"{args.output_dir}/step_by_step_results.csv"
        results_df.to_csv(results_path, index=False)
        print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜: {results_path}")
        
        # ä¿å­˜äº•æ±‡æ€»
        summary_df = pd.DataFrame(well_summaries)
        summary_path = f"{args.output_dir}/well_summary.csv"
        summary_df.to_csv(summary_path, index=False)
        print(f"ğŸ“„ äº•æ±‡æ€»å·²ä¿å­˜: {summary_path}")
        
        # æ•´ä½“ç»Ÿè®¡
        print(f"\nğŸ“Š é€’å½’é¢„æµ‹æ•´ä½“è¯„ä¼°:")
        print(f"   æµ‹è¯•äº•æ•°: {len(well_summaries)}")
        print(f"   æ€»é¢„æµ‹æ¬¡æ•°: {len(all_results)}")
        print(f"   å¹³å‡æ¯äº•é¢„æµ‹æ¬¡æ•°: {len(all_results)/len(well_summaries):.1f}")
        print(f"\n   æ•´ä½“å¹³å‡æŒ‡æ ‡:")
        print(f"   - MAE: {summary_df['overall_MAE'].mean():.2f}")
        print(f"   - RMSE: {summary_df['overall_RMSE'].mean():.2f}")
        print(f"   - MAPE: {summary_df['overall_MAPE'].mean():.2f}%")
        
        print(f"\n   æŒ‰é¢„æµ‹æ­¥æ•°çš„æŒ‡æ ‡å˜åŒ–:")
        step_stats = results_df.groupby('step').agg({
            'MAE': 'mean',
            'RMSE': 'mean',
            'MAPE': 'mean'
        }).reset_index()
        for _, row in step_stats.head(10).iterrows():
            print(f"   æ­¥éª¤ {int(row['step'])}: MAE={row['MAE']:.2f}, "
                  f"RMSE={row['RMSE']:.2f}, MAPE={row['MAPE']:.2f}%")
        
        # ä¿å­˜æ­¥éª¤ç»Ÿè®¡
        step_stats_path = f"{args.output_dir}/step_statistics.csv"
        step_stats.to_csv(step_stats_path, index=False)
        print(f"\nğŸ“„ æ­¥éª¤ç»Ÿè®¡å·²ä¿å­˜: {step_stats_path}")
    
    print(f"\nâœ… é€’å½’é¢„æµ‹æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {args.output_dir}")

if __name__ == "__main__":
    main()

