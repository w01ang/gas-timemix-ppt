#!/usr/bin/env python3
"""
TimeMixer æ»‘åŠ¨çª—å£è®­ç»ƒè„šæœ¬
ä½¿ç”¨å›ºå®šinput_lenå’Œoutput_lençš„æ»‘åŠ¨çª—å£è¿›è¡Œè®­ç»ƒ
"""

import os
import sys
import argparse
import json
import datetime
from pathlib import Path
import platform

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast
from argparse import Namespace
import torch

def train_sliding_window_model(args):
    """è®­ç»ƒæ»‘åŠ¨çª—å£æ¨¡å‹"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒæ»‘åŠ¨çª—å£TimeMixeræ¨¡å‹...")
    print(f"ğŸ“Š é…ç½®å‚æ•°:")
    print(f"   æ¨¡å‹ID: {args.model_id}")
    print(f"   è¾“å…¥é•¿åº¦ (input_len): {args.seq_len}")
    print(f"   è¾“å‡ºé•¿åº¦ (output_len): {args.pred_len}")
    print(f"   æ»‘åŠ¨æ­¥é•¿ (step_len): {args.step_len}")
    print(f"   æ¯”ä¾‹: {args.seq_len}:{args.pred_len} = {args.seq_len/args.pred_len:.2f}:1")
    print(f"   æ¨¡å‹ç»´åº¦: {args.d_model}")
    print(f"   è®­ç»ƒè½®æ•°: {args.train_epochs}")
    
    # åˆ›å»ºå®éªŒå¯¹è±¡
    exp = Exp_Long_Term_Forecast(args)
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\nğŸ”„ å¼€å§‹è®­ç»ƒ...")
    exp.train(args.model_id)
    
    print(f"âœ… æ»‘åŠ¨çª—å£æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: checkpoints/{args.model_id}/")

def main():
    parser = argparse.ArgumentParser(description='TimeMixer æ»‘åŠ¨çª—å£è®­ç»ƒè„šæœ¬')
    
    # å®éªŒæ ‡è¯†
    parser.add_argument('--model_id', type=str, required=True, help='å®éªŒIDï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰')
    parser.add_argument('--comment', type=str, default='sliding_window', help='å®éªŒæ³¨é‡Š')
    parser.add_argument('--description', type=str, default='Sliding window model', help='å®éªŒæè¿°')
    
    # æ•°æ®è·¯å¾„
    parser.add_argument('--root_path', type=str, default='/Users/wangjr/Documents/yk/timemixer/data', 
                        help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--data_path', type=str, default='preprocessed_daily_gas_by_well.csv', 
                        help='æ•°æ®é›†æ–‡ä»¶å')
    
    # æ ¸å¿ƒçª—å£å‚æ•°
    parser.add_argument('--input_len', type=int, required=True, 
                        help='è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆå›ºå®šï¼‰')
    parser.add_argument('--output_len', type=int, required=True, 
                        help='è¾“å‡ºåºåˆ—é•¿åº¦ï¼ˆå›ºå®šï¼‰')
    parser.add_argument('--step_len', type=int, default=None, 
                        help='æ»‘åŠ¨çª—å£æ­¥é•¿ï¼ˆé»˜è®¤=output_lenï¼Œå³æ— é‡å ï¼‰')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--d_model', type=int, default=256, help='æ¨¡å‹ç»´åº¦')
    parser.add_argument('--n_heads', type=int, default=16, help='æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--e_layers', type=int, default=6, help='ç¼–ç å™¨å±‚æ•°')
    parser.add_argument('--d_layers', type=int, default=3, help='è§£ç å™¨å±‚æ•°')
    parser.add_argument('--d_ff', type=int, default=1024, help='å‰é¦ˆç½‘ç»œç»´åº¦')
    parser.add_argument('--use_gpu', action='store_true', help='å¯ç”¨GPU/MPSåŠ é€Ÿ')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--train_epochs', type=int, default=100, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹å¤§å°')
    parser.add_argument('--patience', type=int, default=20, help='æ—©åœè€å¿ƒå€¼')
    parser.add_argument('--learning_rate', type=float, default=1e-4, help='å­¦ä¹ ç‡')
    
    args = parser.parse_args()
    
    # è®¾ç½®é»˜è®¤æ­¥é•¿
    if args.step_len is None:
        args.step_len = args.output_len
        print(f"â„¹ï¸  æ­¥é•¿æœªæŒ‡å®šï¼Œä½¿ç”¨é»˜è®¤å€¼: step_len = output_len = {args.step_len}")
    
    # æ˜¾ç¤ºå‚æ•°ä¿¡æ¯
    print(f"\nğŸ“Š æ»‘åŠ¨çª—å£é…ç½®:")
    print(f"   è¾“å…¥é•¿åº¦ (input_len): {args.input_len}")
    print(f"   è¾“å‡ºé•¿åº¦ (output_len): {args.output_len}")
    print(f"   æ»‘åŠ¨æ­¥é•¿ (step_len): {args.step_len}")
    print(f"   çª—å£æ€»é•¿åº¦: {args.input_len + args.output_len}")
    
    if args.step_len < args.output_len:
        overlap = args.output_len - args.step_len
        overlap_pct = (overlap / args.output_len) * 100
        print(f"   çª—å£é‡å : {overlap} æ­¥ ({overlap_pct:.1f}%)")
    elif args.step_len == args.output_len:
        print(f"   çª—å£é‡å : æ— é‡å ï¼ˆç›¸é‚»çª—å£ï¼‰")
    else:
        gap = args.step_len - args.output_len
        print(f"   çª—å£é—´éš™: {gap} æ­¥")
    
    print(f"   è¾“å…¥:è¾“å‡ºæ¯”ä¾‹ = {args.input_len}:{args.output_len} = {args.input_len/args.output_len:.2f}:1")
    
    # æ„å»ºæ¨¡å‹é…ç½®
    model_args = Namespace(
        task_name='long_term_forecast',
        is_training=1,
        model_id=args.model_id,
        model='TimeMixer',
        data='WELLS',
        root_path=args.root_path,
        data_path=args.data_path,
        features='S',
        target='OT',
        freq='d',
        checkpoints='./checkpoints/',
        seq_len=args.input_len,      # è¾“å…¥é•¿åº¦
        label_len=args.output_len,   # æ ‡ç­¾é•¿åº¦ï¼ˆé€šå¸¸ç­‰äºpred_lenï¼‰
        pred_len=args.output_len,    # é¢„æµ‹é•¿åº¦
        step_len=args.step_len,      # æ»‘åŠ¨æ­¥é•¿ï¼ˆæ–°å¢å‚æ•°ï¼‰
        seasonal_patterns='Monthly',
        inverse=True,
        top_k=5,
        num_kernels=6,
        enc_in=1,
        dec_in=1,
        c_out=1,
        d_model=args.d_model,
        n_heads=args.n_heads,
        e_layers=args.e_layers,
        d_layers=args.d_layers,
        d_ff=args.d_ff,
        moving_avg=49,
        factor=1,
        distil=True,
        dropout=0.1,
        embed='timeF',
        activation='gelu',
        output_attention=False,
        channel_independence=1,
        decomp_method='moving_avg',
        use_norm=1,
        down_sampling_layers=1,
        down_sampling_window=2,
        down_sampling_method='avg',
        use_future_temporal_feature=0,
        mask_rate=0.125,
        anomaly_ratio=0.25,
        num_workers=0,
        itr=1,
        train_epochs=args.train_epochs,
        batch_size=args.batch_size,
        patience=args.patience,
        learning_rate=args.learning_rate,
        des=args.description,
        loss='MSE',
        drop_last=True,
        lradj='TST',
        pct_start=0.2,
        use_amp=False,
        comment=args.comment,
        use_gpu=args.use_gpu,
        gpu=0,
        use_multi_gpu=False,
        devices='0,1',
        p_hidden_dims=[128, 128],
        p_hidden_layers=2
    )

    # è‡ªåŠ¨æ£€æµ‹GPUå¯ç”¨æ€§
    if model_args.use_gpu and platform.system() == 'Darwin':
        if not torch.backends.mps.is_available():
            print('âš ï¸  MPSä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU')
            model_args.use_gpu = False
        else:
            print('âœ… ä½¿ç”¨MPSåŠ é€Ÿ')
    elif model_args.use_gpu and torch.cuda.is_available():
        print('âœ… ä½¿ç”¨CUDAåŠ é€Ÿ')
    elif model_args.use_gpu:
        print('âš ï¸  GPUä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU')
        model_args.use_gpu = False
    
    # ä¿å­˜å®éªŒé…ç½®
    config_dir = f"experiments/{args.model_id}"
    os.makedirs(config_dir, exist_ok=True)
    
    config = {
        "model_id": args.model_id,
        "comment": args.comment,
        "description": args.description,
        "input_len": args.input_len,
        "output_len": args.output_len,
        "step_len": args.step_len,
        "window_total_len": args.input_len + args.output_len,
        "input_output_ratio": args.input_len / args.output_len,
        "d_model": args.d_model,
        "n_heads": args.n_heads,
        "e_layers": args.e_layers,
        "d_layers": args.d_layers,
        "d_ff": args.d_ff,
        "train_epochs": args.train_epochs,
        "batch_size": args.batch_size,
        "patience": args.patience,
        "learning_rate": args.learning_rate,
        "use_gpu": model_args.use_gpu,
        "root_path": args.root_path,
        "data_path": args.data_path,
        "created_at": datetime.datetime.now().isoformat()
    }
    
    with open(f"{config_dir}/config.json", 'w') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“ é…ç½®å·²ä¿å­˜åˆ°: {config_dir}/config.json")
    
    # å¼€å§‹è®­ç»ƒ
    train_sliding_window_model(model_args)

if __name__ == "__main__":
    main()

